<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>TTS Demo with Speech Input</title>
  <!-- PWA manifest for basic PWA support -->
  <link rel="manifest" href="manifest.json">
  <style>
    body { font-family: Arial, sans-serif; padding: 20px; max-width: 600px; margin: 0 auto; }
    input, select, button { margin: 10px 0; padding: 8px; width: 100%; font-size: 16px; }
    button { background-color: #007bff; color: white; border: none; cursor: pointer; }
    button:hover { background-color: #0056b3; }
    #speechButton.listening { background-color: #dc3545; } /* Red when listening */
  </style>
</head>
<body>
  <h1>Text-to-Speech Demo</h1>
  <input type="text" id="textInput" placeholder="Enter text to speak" value="Hello! This is a text-to-speech demo.">
  <select id="voiceSelect" aria-label="Select voice"></select>
  <button onclick="speak()">Speak</button>
  <button onclick="stopSpeech()">Stop</button>
  <button id="speechButton" onclick="toggleSpeechRecognition()">Start Speech Input</button>

  <script>
    const textInput = document.getElementById('textInput');
    const voiceSelect = document.getElementById('voiceSelect');
    const speechButton = document.getElementById('speechButton');
    let voices = [];
    let isListening = false;

    // Load available voices
    function loadVoices() {
      voices = window.speechSynthesis.getVoices();
      voiceSelect.innerHTML = ''; // Clear previous options
      voices.forEach((voice, i) => {
        const option = document.createElement('option');
        option.value = i;
        option.textContent = `${voice.name} (${voice.lang})`;
        voiceSelect.appendChild(option);
      });
    }

    // Populate voices when available (may be async)
    window.speechSynthesis.onvoiceschanged = loadVoices;
    loadVoices(); // Initial call in case voices are already loaded

    // Speak function
    function speak() {
      if (!textInput.value) return;
      const utterance = new SpeechSynthesisUtterance(textInput.value);
      
      // Set selected voice
      const selectedVoice = voices[voiceSelect.value];
      if (selectedVoice) utterance.voice = selectedVoice;
      
      utterance.lang = selectedVoice?.lang || 'en-US';
      utterance.pitch = 1;
      utterance.rate = 1;
      utterance.volume = 1;

      // Handle errors
      utterance.onerror = (event) => console.error('Speech error:', event.error);
      
      window.speechSynthesis.speak(utterance);
    }

    // Stop speech
    function stopSpeech() {
      window.speechSynthesis.cancel();
    }

    // Speech Recognition Setup
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition;

    if (SpeechRecognition) {
      recognition = new SpeechRecognition();
      recognition.lang = 'en-US';
      recognition.interimResults = true; // Show partial results
      recognition.continuous = true; // Keep listening until stopped

      // Handle results
      recognition.onresult = (event) => {
        let transcript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          transcript += event.results[i][0].transcript;
        }
        textInput.value = transcript; // Update input with interim or final results
      };

      // Handle errors
      recognition.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        if (event.error !== 'aborted') {
          alert('Speech recognition error: ' + event.error);
        }
      };

      // Handle end of recognition
      recognition.onend = () => {
        console.log('Speech recognition ended');
        if (isListening) {
          try {
            recognition.start(); // Restart if still supposed to be listening
          } catch (e) {
            console.error('Error restarting recognition:', e);
            stopListening(); // Reset state if restart fails
          }
        } else {
          stopListening(); // Ensure button reflects stopped state
        }
      };
    } else {
      console.warn('SpeechRecognition not supported in this browser.');
      alert('Speech recognition is not supported in your browser.');
      speechButton.disabled = true; // Disable button if unsupported
    }

    // Toggle speech recognition
    function toggleSpeechRecognition() {
      if (!recognition) return;

      if (isListening) {
        recognition.abort(); // Stop immediately
        stopListening();
      } else {
        try {
          recognition.start();
          startListening();
        } catch (e) {
          console.error('Error starting recognition:', e);
          alert('Could not start speech recognition: ' + e.message);
        }
      }
    }

    // Start listening state
    function startListening() {
      isListening = true;
      speechButton.textContent = 'Stop Speech Input';
      speechButton.classList.add('listening');
      console.log('Speech recognition started');
    }

    // Stop listening state
    function stopListening() {
      isListening = false;
      speechButton.textContent = 'Start Speech Input';
      speechButton.classList.remove('listening');
      console.log('Speech recognition stopped');
    }
  </script>
</body>
</html>